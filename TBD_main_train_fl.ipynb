{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from learning_util import load_dataset, preprocess, create_fl_dataset, create_model, save_ckpt, load_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = _ = None\n",
    "STIME = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed arguments Namespace(batch_size=32, ckpt_load=False, ckpt_term=10, debug=True, img_height=375, img_width=4, input='ieeeaccess', max_rounds=5, nclients=10, num_epochs=1, output='output', shuffle_buffer=1024, val_size=0.1)\n",
      "Unparsed arguments ['-f', '/home/harny/.local/share/jupyter/runtime/kernel-958b26af-965a-40ce-99b6-21451f11628b.json']\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "FLAGS, _ = parser.parse_known_args()\n",
    "\n",
    "FLAGS.debug = True\n",
    "FLAGS.img_width = 4\n",
    "FLAGS.img_height = 375\n",
    "FLAGS.input = 'ieeeaccess'\n",
    "FLAGS.nclients = 10\n",
    "FLAGS.val_size = 0.1\n",
    "FLAGS.batch_size = 32\n",
    "FLAGS.shuffle_buffer = 1024\n",
    "FLAGS.num_epochs = 1\n",
    "FLAGS.max_rounds = 5\n",
    "FLAGS.output = 'output'\n",
    "FLAGS.ckpt_load = False\n",
    "FLAGS.ckpt_term = 10\n",
    "\n",
    "DEBUG = FLAGS.debug\n",
    "\n",
    "if DEBUG:\n",
    "    print(f'Parsed arguments {FLAGS}')\n",
    "    print(f'Unparsed arguments {_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         idx           lab                                             vector\n",
      "0       [14]  [voipbuster]  [[69, 0, 0, 111, 112, 133, 64, 0, 128, 17, 161...\n",
      "1        [9]        [sftp]  [[69, 0, 5, 220, 26, 42, 64, 0, 128, 6, 242, 1...\n",
      "2        [3]        [ftps]  [[69, 0, 5, 220, 115, 38, 64, 0, 128, 6, 153, ...\n",
      "3        [5]     [hangout]  [[69, 0, 3, 229, 121, 214, 0, 0, 128, 17, 0, 0...\n",
      "4       [14]  [voipbuster]  [[69, 0, 0, 111, 5, 100, 64, 0, 128, 17, 12, 5...\n",
      "...      ...           ...                                                ...\n",
      "163323   [6]     [icqchat]  [[69, 0, 0, 78, 24, 198, 0, 0, 128, 17, 53, 23...\n",
      "163324   [6]     [icqchat]  [[69, 0, 0, 50, 83, 46, 0, 0, 1, 17, 17, 111, ...\n",
      "163325   [6]     [icqchat]  [[69, 0, 0, 114, 109, 12, 64, 0, 128, 6, 113, ...\n",
      "163326   [6]     [icqchat]  [[69, 0, 0, 114, 45, 244, 64, 0, 128, 6, 176, ...\n",
      "163327   [6]     [icqchat]  [[69, 0, 0, 50, 83, 48, 0, 0, 1, 17, 17, 109, ...\n",
      "\n",
      "[163328 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset, idx2lab, idx2cnt = load_dataset(FLAGS.input)\n",
    "if DEBUG:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         idx        lab                                             vector  \\\n",
      "0       [15]  [youtube]  [[69, 0, 10, 168, 213, 50, 0, 0, 58, 6, 76, 60...   \n",
      "1        [7]  [netflix]  [[69, 0, 10, 168, 156, 47, 64, 0, 52, 6, 147, ...   \n",
      "2        [4]    [gmail]  [[69, 0, 0, 65, 103, 68, 0, 0, 128, 17, 254, 1...   \n",
      "3       [15]  [youtube]  [[69, 0, 10, 168, 111, 0, 0, 0, 58, 6, 178, 11...   \n",
      "4       [15]  [youtube]  [[69, 0, 15, 226, 143, 225, 0, 0, 58, 6, 140, ...   \n",
      "...      ...        ...                                                ...   \n",
      "163323  [12]  [torrent]  [[69, 0, 5, 110, 16, 58, 64, 0, 49, 6, 11, 114...   \n",
      "163324   [4]    [gmail]  [[69, 0, 5, 110, 110, 228, 64, 0, 128, 6, 229,...   \n",
      "163325  [13]    [vimeo]  [[69, 0, 0, 235, 244, 242, 64, 0, 49, 6, 153, ...   \n",
      "163326   [4]    [gmail]  [[69, 0, 3, 255, 101, 7, 0, 0, 128, 17, 48, 16...   \n",
      "163327  [10]    [skype]  [[69, 0, 0, 55, 126, 123, 0, 0, 64, 17, 123, 2...   \n",
      "\n",
      "                                                        x     y  \n",
      "0       [[[0.27058823529411763], [0.0], [0.03921568627...  [15]  \n",
      "1       [[[0.27058823529411763], [0.0], [0.03921568627...   [7]  \n",
      "2       [[[0.27058823529411763], [0.0], [0.0], [0.2549...   [4]  \n",
      "3       [[[0.27058823529411763], [0.0], [0.03921568627...  [15]  \n",
      "4       [[[0.27058823529411763], [0.0], [0.05882352941...  [15]  \n",
      "...                                                   ...   ...  \n",
      "163323  [[[0.27058823529411763], [0.0], [0.01960784313...  [12]  \n",
      "163324  [[[0.27058823529411763], [0.0], [0.01960784313...   [4]  \n",
      "163325  [[[0.27058823529411763], [0.0], [0.0], [0.9215...  [13]  \n",
      "163326  [[[0.27058823529411763], [0.0], [0.01176470588...   [4]  \n",
      "163327  [[[0.27058823529411763], [0.0], [0.0], [0.2156...  [10]  \n",
      "\n",
      "[163328 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "img_shape = (FLAGS.img_height, FLAGS.img_width, 1) # gray scale\n",
    "\n",
    "dataset['x'] = dataset['vector'].apply(preprocess(img_shape))\n",
    "dataset['y'] = dataset['idx']\n",
    "\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "if DEBUG:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split train dataset 14691\n",
      "split test dataset 16402\n"
     ]
    }
   ],
   "source": [
    "raw_train_datasets, raw_test_dataset = create_fl_dataset(\n",
    "    dataset, idx2lab, FLAGS.nclients, FLAGS.val_size, printable=DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(client_id):\n",
    "    return raw_train_datasets[client_id].repeat(FLAGS.num_epochs).shuffle(FLAGS.shuffle_buffer).batch(FLAGS.batch_size)\n",
    "\n",
    "client_data = tff.simulation.ClientData.from_clients_and_fn(\n",
    "    client_ids=range(0, len(raw_train_datasets)),\n",
    "    create_tf_dataset_for_client_fn=client_fn)\n",
    "client_data = [client_data.create_tf_dataset_for_client(x) for x in range(0, len(raw_train_datasets))]\n",
    "\n",
    "test_dataset = raw_test_dataset.shuffle(FLAGS.shuffle_buffer).batch(FLAGS.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    keras_model = create_model(len(idx2lab), img_shape)\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=test_dataset.element_spec,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harny/Jupyter/tff/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1659: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "        model_fn,\n",
    "        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'rounds': 0,\n",
    "    'loss': list(),\n",
    "    'accuracy': list(),\n",
    "    'val_loss': list(),\n",
    "    'val_accuracy': list(),\n",
    "}\n",
    "path_output = os.path.join(FLAGS.output, f'c{FLAGS.nclients}_e{FLAGS.num_epochs}_r{FLAGS.max_rounds}')\n",
    "if FLAGS.ckpt_load:\n",
    "    state, metrics = load_ckpt(path_output, state)\n",
    "    if DEBUG:\n",
    "        print(f'Load completed: rounds {metrics[\"rounds\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[513] rounds: 1, output: OrderedDict([('sparse_categorical_accuracy', 0.52367437), ('loss', 1.4520663)]), val_output: OrderedDict([('sparse_categorical_accuracy', 0.76880866), ('loss', 0.96667546)])\n",
      "[637] rounds: 2, output: OrderedDict([('sparse_categorical_accuracy', 0.7692533), ('loss', 0.8171528)]), val_output: OrderedDict([('sparse_categorical_accuracy', 0.82806975), ('loss', 0.615555)])\n",
      "[769] rounds: 3, output: OrderedDict([('sparse_categorical_accuracy', 0.8396978), ('loss', 0.581441)]), val_output: OrderedDict([('sparse_categorical_accuracy', 0.846665), ('loss', 0.561372)])\n",
      "[906] rounds: 4, output: OrderedDict([('sparse_categorical_accuracy', 0.86943024), ('loss', 0.476544)]), val_output: OrderedDict([('sparse_categorical_accuracy', 0.8886721), ('loss', 0.43721974)])\n",
      "[1044] rounds: 5, output: OrderedDict([('sparse_categorical_accuracy', 0.88738), ('loss', 0.41798744)]), val_output: OrderedDict([('sparse_categorical_accuracy', 0.87733203), ('loss', 0.44450983)])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c27491543c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_term\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msave_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msave_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx2lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Github/tff-app/learning_util.py\u001b[0m in \u001b[0;36msave_ckpt\u001b[0;34m(path, state, metrics, func, *args)\u001b[0m\n\u001b[1;32m     93\u001b[0m     keras_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n\u001b[1;32m     94\u001b[0m                         metrics=[tf.keras.metrics.CategoricalAccuracy()])\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mtff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_weights_to_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tff' is not defined"
     ]
    }
   ],
   "source": [
    "for rounds in range(metrics['rounds']+1, FLAGS.max_rounds+1):\n",
    "    state, output = iterative_process.next(state, client_data)\n",
    "    val_output = evaluation(state.model, [test_dataset])\n",
    "    metrics['rounds'] = rounds\n",
    "    metrics['loss'].append(output['train']['loss'])\n",
    "    metrics['accuracy'].append(output['train']['sparse_categorical_accuracy'])\n",
    "    metrics['val_loss'].append(val_output['loss'])\n",
    "    metrics['val_accuracy'].append(val_output['sparse_categorical_accuracy'])\n",
    "    if DEBUG:\n",
    "        print((f'[{int(time.time()-STIME)}] rounds: {rounds}, '\n",
    "               f'output: {output[\"train\"]}, '\n",
    "               f'val_output: {val_output}'))\n",
    "    if rounds%FLAGS.ckpt_term == 0:\n",
    "        save_ckpt(path_output, state, metrics, create_model, len(idx2lab), img_shape)\n",
    "save_ckpt(path_output, state, metrics, create_model, len(idx2lab), img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Federated",
   "language": "python",
   "name": "tff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
