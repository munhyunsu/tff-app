{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib widget\n",
    "%matplotlib inline\n",
    "\n",
    "from scapy.all import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate packet size\n",
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pcap files\n",
    "def read_pcap(root_dir, ext=('.pcap', '.pcapng')):\n",
    "    queue = [root_dir]\n",
    "    while len(queue) != 0:\n",
    "        nest_dir = queue.pop()\n",
    "        with os.scandir(nest_dir) as it:\n",
    "            for entry in it:\n",
    "                if not entry.name.startswith('.') and entry.is_file():\n",
    "                    if entry.name.endswith(ext):\n",
    "                        label = os.path.basename(os.path.dirname(entry.path)) # dirname is label\n",
    "                        yield label, entry.path\n",
    "                elif not entry.name.startswith('.') and entry.is_dir():\n",
    "                    queue.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DATA = './dataset/pcap_data_splited'\n",
    "\n",
    "def pkt2img(label, cnt):\n",
    "    def process_pkt(pkt):\n",
    "        if not pkt.haslayer('IP'):\n",
    "            return\n",
    "        ip = pkt['IP']\n",
    "        if not (ip.haslayer('TCP') or ip.haslayer('UDP')):\n",
    "            return\n",
    "        if ip.haslayer('TCP'):\n",
    "            l4 = 'TCP'\n",
    "        elif ip.haslayer('UDP'):\n",
    "            l4 = 'UDP'\n",
    "        if label not in cnt.keys():\n",
    "            cnt[label] = dict()\n",
    "        size = len(raw(ip[l4].payload))\n",
    "        cnt[label][size] = cnt[label].get(size, 0) + 1\n",
    "    return process_pkt\n",
    "\n",
    "splited_path = os.path.abspath(os.path.expanduser(SPLIT_DATA))\n",
    "cnt = dict()\n",
    "for label, path in read_pcap(splited_path):\n",
    "    print(f'Current processing: {label} {path}', end='\\r')\n",
    "    sniff(offline=path, prn=pkt2img(label, cnt), store=False)\n",
    "\n",
    "cntl = dict()\n",
    "for label, value in cnt.items():\n",
    "    cntl[label] = pd.DataFrame(sorted(value.items()), columns=['size', 'count'])\n",
    "    \n",
    "# with open('packetsize.pickle', 'wb') as f:\n",
    "#     pickle.dump(cntl, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Packet size chart\n",
    "## Restore packet size pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('packetsize.pickle', 'rb') as f:\n",
    "#     cntl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(16, 4.5), tight_layout=True)\n",
    "\n",
    "lkey = len(cntl.keys())\n",
    "i = 0\n",
    "\n",
    "for label in sorted(cntl.keys()):\n",
    "    ax = fig1.add_subplot(2, lkey//2, i+1)\n",
    "    ax.stem(cntl[label]['size'], cntl[label]['count'],\n",
    "            markerfmt='None', linefmt='darkgray',\n",
    "            use_line_collection=True)\n",
    "    td = cntl[label][cntl[label]['size']>=152]\n",
    "    ax.stem(td['size'], td['count'],\n",
    "            markerfmt='None', linefmt='dimgray',\n",
    "            use_line_collection=True)\n",
    "    orate = round(td.shape[0] / cntl[label].shape[0], 2)\n",
    "    ax.text(1500, 10**4*1.5, orate, color='black')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlim([0, 2000])\n",
    "    ax.set_xticks([0, 500, 1000, 1500, 2000])\n",
    "    ax.set_ylim([1, 10**5*1.1])\n",
    "    ax.set_yticks([10**x for x in range(1, 6)])\n",
    "    ax.set_xlabel(f'{label} ({round(cntl[label].shape[0]/1000, 2)}k)', size='x-large')\n",
    "    ax.margins(10, 1000)\n",
    "    if i%(lkey//2) != 0:\n",
    "        ax.set_yticklabels([])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of packets by applications')\n",
    "for label in sorted(cntl.keys()):\n",
    "    print(f'{label} {sum(cntl[label][\"count\"])}')\n",
    "print('The number of packets over size 1148 by applications')\n",
    "for label in sorted(cntl.keys()):\n",
    "    td = cntl[label][cntl[label]['size']>=1184]\n",
    "    print(f'{label} {sum(td[\"count\"])}')\n",
    "print(f'The sum of packets {sum(cntl[label]['count'])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Federated Learning",
   "language": "python",
   "name": "tff-app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
