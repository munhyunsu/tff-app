{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.1.0\n",
      "Tensorflow Federated version: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from operator import itemgetter\n",
    "import collections\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Tensorflow Federated version: {tff.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "# Setup scripts (or notebook)\n",
    "IMG_DATA = './federated_data_5_balanced_iid'\n",
    "VAL_DATA = './sampled_data_1184'\n",
    "IMG_SHAPE = (39, 39)\n",
    "MAX_STEPS = 1000\n",
    "CLASSES = ['aim', 'email', 'facebook', 'ftps', 'gmail', \n",
    "           'hangout', 'icqchat', 'netflix', 'scp', 'sftp',\n",
    "           'skype', 'spotify', 'torrent', 'vimeo', 'voipbuster',\n",
    "           'youtube']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset root: /home/harny/Github/tff-app/federated_data_5_balanced_iid\n",
      "CPU times: user 131 ms, sys: 5.05 ms, total: 136 ms\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare dataset\n",
    "dataset_root = os.path.abspath(os.path.expanduser(IMG_DATA))\n",
    "print(f'Dataset root: {dataset_root}')\n",
    "\n",
    "img_gen_op = {'classes': CLASSES, 'target_size': IMG_SHAPE}\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "def gen_fn(args):\n",
    "    data_path = args.decode('utf-8')\n",
    "    return image_generator.flow_from_directory(data_path,\n",
    "                                               **img_gen_op)\n",
    "\n",
    "dataset_dict = dict()\n",
    "with os.scandir(dataset_root) as it:\n",
    "    for entry in it:\n",
    "        if entry.is_dir():\n",
    "            name = os.path.basename(entry.path)\n",
    "            ds = tf.data.Dataset.from_generator(gen_fn,\n",
    "                                                args=[entry.path],\n",
    "                                                output_types=(tf.float32, tf.float32),\n",
    "                                                output_shapes=(tf.TensorShape([None, 39, 39, 3]), \n",
    "                                                               tf.TensorShape([None, 16]))\n",
    "                                               )\n",
    "            dataset_dict[name] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_fn(client_id):\n",
    "    return dataset_dict[client_id]\n",
    "\n",
    "client_data = tff.simulation.ClientData.from_clients_and_fn(\n",
    "                client_ids=list(dataset_dict.keys()),\n",
    "                create_tf_dataset_for_client_fn=client_fn)\n",
    "\n",
    "train_ids = list(dataset_dict.keys())\n",
    "train_ids.remove('0')\n",
    "dataset = [client_data.create_tf_dataset_for_client(x) for x in train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FlatMapDataset shapes: ((None, 39, 39, 3), (None, 16)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "example_dataset = client_data.create_tf_dataset_for_client(client_data.client_ids[0])\n",
    "print(example_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11257 images belonging to 16 classes.\n",
      "(32, 39, 39, 3) (32, 16)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(dataset):\n",
    "    return dataset.take(32*10).cache().repeat(1)\n",
    "preprocessed_example_dataset = preprocess(example_dataset)\n",
    "sample_batch = tf.nest.map_structure(lambda x: x.numpy(), iter(preprocessed_example_dataset).next())\n",
    "print(sample_batch[0].shape, sample_batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_dataset = [preprocess(x) for x in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_compiled_keras_model():\n",
    "    base_learning_rate = 0.001 # default\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "                    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=IMG_SHAPE + (3, )),\n",
    "                    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "                    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                    tf.keras.layers.Flatten(),\n",
    "                    tf.keras.layers.Dense(64, activation='relu'),\n",
    "                    tf.keras.layers.Dense(len(CLASSES))])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    keras_model = create_compiled_keras_model()\n",
    "    return tff.learning.from_compiled_keras_model(keras_model, sample_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/harny/Github/tff-app/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harny/Github/tff-app/venv/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py:242: UserWarning: tff.learning.build_federated_averaging_process will start requiring a new argument 'client_optimizer_fn'. Specify the local client optimizer here rather than building a ttf.learning.TrainableModel\n",
      "  warnings.warn('tff.learning.build_federated_averaging_process will start '\n",
      "/home/harny/Github/tff-app/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: from_compiled_keras_model is deprecated, use from_keras_model with an uncompiled model\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/harny/Github/tff-app/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: from_compiled_keras_model is deprecated, use from_keras_model with an uncompiled model\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( -> <model=<trainable=<float32[3,3,3,32],float32[32],float32[3,3,32,64],float32[64],float32[3,3,64,64],float32[64],float32[2304,64],float32[64],float32[64,16],float32[16]>,non_trainable=<>>,optimizer_state=<int64>,delta_aggregate_state=<>,model_broadcast_state=<>>@SERVER)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(iterative_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11257 images belonging to 16 classes.\n",
      "Found 11256 images belonging to 16 classes.\n",
      "Found 11245 images belonging to 16 classes.Found 11248 images belonging to 16 classes.\n",
      "\n",
      "Found 11258 images belonging to 16 classes.\n",
      "round  1, metrics=<categorical_accuracy=0.6935351490974426,loss=1.2649835348129272,keras_training_time_client_sum_sec=0.0061228275299072266>\n"
     ]
    }
   ],
   "source": [
    "state, metrics = iterative_process.next(state, federated_dataset)\n",
    "print('round  1, metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  2, metrics=<categorical_accuracy=0.768359363079071,loss=1.0161627531051636,keras_training_time_client_sum_sec=0.007855892181396484>\n",
      "round  3, metrics=<categorical_accuracy=0.7726171612739563,loss=0.9662094116210938,keras_training_time_client_sum_sec=0.00530242919921875>\n",
      "round  4, metrics=<categorical_accuracy=0.7770702838897705,loss=0.9449036121368408,keras_training_time_client_sum_sec=0.0047206878662109375>\n",
      "round  5, metrics=<categorical_accuracy=0.7808789014816284,loss=0.9135715365409851,keras_training_time_client_sum_sec=0.005410909652709961>\n",
      "round  6, metrics=<categorical_accuracy=0.824999988079071,loss=0.6124383211135864,keras_training_time_client_sum_sec=0.005804538726806641>\n",
      "round  7, metrics=<categorical_accuracy=0.8448241949081421,loss=0.5104010701179504,keras_training_time_client_sum_sec=0.004790306091308594>\n",
      "round  8, metrics=<categorical_accuracy=0.8627734184265137,loss=0.4376815855503082,keras_training_time_client_sum_sec=0.004714012145996094>\n",
      "round  9, metrics=<categorical_accuracy=0.88037109375,loss=0.3800087869167328,keras_training_time_client_sum_sec=0.005108356475830078>\n",
      "round 10, metrics=<categorical_accuracy=0.8974804878234863,loss=0.3271383047103882,keras_training_time_client_sum_sec=0.005525827407836914>\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 11\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "    state, metrics = iterative_process.next(state, federated_dataset)\n",
    "    print('round {:2d}, metrics={}'.format(round_num, metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation\n",
    "test_dataset = client_data.create_tf_dataset_for_client('0')\n",
    "federated_test_data = [preprocess(test_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harny/Github/tff-app/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: from_compiled_keras_model is deprecated, use from_keras_model with an uncompiled model\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "evaluation = tff.learning.build_federated_evaluation(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11258 images belonging to 16 classes.\n",
      "<categorical_accuracy=0.9083007574081421,loss=0.29094889760017395,keras_training_time_client_sum_sec=0.0>\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluation(state.model, federated_test_data)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Federated Learning",
   "language": "python",
   "name": "tff-app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
