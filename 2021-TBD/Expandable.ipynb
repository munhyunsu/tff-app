{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ffdea-f6ef-48df-bb75-1ef36e402c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbb6a3-d256-49e0-b9e7-100562d0c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Tensorflow 버전을 확인합니다: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f882a4-eb8b-480a-9e13-19c9cf382bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(_train_images, train_labels), (_test_images, test_labels) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd1eef-b40a-4bac-8f86-650321070f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'학습에 사용할 이미지는 {len(_train_images)}개 입니다.')\n",
    "print(f'학습한 후 테스트(검증)에 사용할 이미지는 {len(_test_images)}개 입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b063c-fdea-4478-b7ee-a46a3e901e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
    "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "print(f'데이터의 레이블은 {len(class_names)}개 이며, 데이터셋에 포함되어 있지 않으므로 설명서에서 확인해야 합니다.')\n",
    "print('레이블 번호와 레이블: ')\n",
    "for i in range(0, len(class_names)):\n",
    "    print(f'{i}: {class_names[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d603536-605b-4350-8e42-0d52b346c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('인공 신경망은 주로 -1.0 ~ 1.0 사이의 값을 받습니다.')\n",
    "print('따라서 이미지를 255로 나누어줍니다.')\n",
    "train_images = _train_images / 255.0\n",
    "test_images = _test_images / 255.0\n",
    "print(f'기존 최소: {np.min(_train_images[0])}, 기존 최대: {np.max(_train_images[0])}')\n",
    "print(f'정규화 후 최소: {np.min(train_images[0])}, 정규화 후 최대: {np.max(train_images[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24254857-2294-42be-b75a-285fa5556175",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.set_facecolor('white')\n",
    "for i in range(25):\n",
    "    ax = fig.add_subplot(5, 5, i+1)\n",
    "    ax.imshow(train_images[i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(class_names[train_labels[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8c307-3c70-467c-9bc0-89eeb1167b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12/5*2))\n",
    "fig.set_facecolor('white')\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    for j in range(10000, len(train_images)):\n",
    "        if train_labels[j] == i:\n",
    "            break\n",
    "    ax.imshow(train_images[j])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f'[{train_labels[j][0]}] {class_names[train_labels[j][0]]}', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207c2665-b1d5-4edc-921a-0079a6af60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_images[0].shape\n",
    "print(f'데이터 상태: {input_shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5148c9d-cd58-4150-a661-c6b77edbf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "T = 2\n",
    "for a, b in zip(train_images, train_labels):\n",
    "    if T < b[0]:\n",
    "        continue\n",
    "    X.append(a)\n",
    "    y.append(b)\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "print(f'{T} 이하 데이터 셋 크기: {X.shape}, {y.shape}')\n",
    "input_shape = X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722f20a-8fb2-4fc6-80ef-30dff703e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(T+1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b1ff1-8d3c-444f-a97e-de8d3efeb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59134099-d2a7-44b3-8cf4-b6718e5c4546",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(T+1)\n",
    "])\n",
    "model_init.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f96d0-6395-4941-9abd-1baa78586b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init.layers[1].set_weights(model.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53710f-9dfb-4ab6-bb49-87c9b59a6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "history = model.fit(X, y, \n",
    "                    epochs=epochs,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d49315-9458-44ec-ae32-35773f916ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4453eeb-4bab-45d0-bef7-e39e80d84842",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd394d8-1f05-418d-bf71-a971449026f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "T = 1\n",
    "\n",
    "for a, b in zip(train_images, train_labels):\n",
    "    if T < b[0]:\n",
    "        continue\n",
    "    X.append(a)\n",
    "    y.append(b)\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "print(f'{T} 이하 데이터 셋 크기: {X.shape}, {y.shape}')\n",
    "input_shape = X[0].shape\n",
    "\n",
    "model_b1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(T+1)\n",
    "])\n",
    "model_b1.summary()\n",
    "model_b1.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "history = model_b1.fit(X, y, \n",
    "                    epochs=epochs,\n",
    "                    verbose=0)\n",
    "model_b1.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfbb9e-99e9-42c0-a501-455dfb42569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "T = 2\n",
    "\n",
    "for a, b in zip(train_images, train_labels):\n",
    "    if T < b[0]:\n",
    "        continue\n",
    "    X.append(a)\n",
    "    y.append(b)\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "print(f'{T} 이하 데이터 셋 크기: {X.shape}, {y.shape}')\n",
    "input_shape = X[0].shape\n",
    "\n",
    "model1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(T+1)\n",
    "])\n",
    "model1.summary()\n",
    "model1.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe595f4-1d94-4d4f-a28b-a89750a70641",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.layers[1].set_weights([np.pad(model_b1.layers[1].get_weights()[0], (0, 1), mode='constant')[:-1, :], \n",
    "                              np.pad(model_b1.layers[1].get_weights()[1], (0, 1), mode='constant')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35ed56-63eb-4c8d-a24c-e76df6391f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "history = model1.fit(X, y, \n",
    "                    epochs=epochs,\n",
    "                    verbose=0)\n",
    "model1.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f64a4-fdcd-4106-ae22-5ab4cdd9717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(T+1)\n",
    "])\n",
    "model2.summary()\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3bfae-c7d8-4ac8-b11a-2d478901c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.layers[1].set_weights([np.pad(model_b1.layers[1].get_weights()[0], (0, 1), mode='constant')[:-1, :], \n",
    "                              np.pad(model_b1.layers[1].get_weights()[1], (0, 1), mode='constant')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc8e39-c655-4b78-900c-9c6e33f59673",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "history = model2.fit(X, y, \n",
    "                    epochs=epochs,\n",
    "                    verbose=0)\n",
    "model2.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4f135-7fdd-492f-b0b2-7a6ca3e5f897",
   "metadata": {},
   "source": [
    "### Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0f551-30e8-4286-99f1-1305ccf92b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need https://github.com/yuanli2333/CKA-Centered-Kernel-Alignment\n",
    "import cca_core\n",
    "from CKA import linear_CKA, kernel_CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad6ff0-8872-47de-b009-a044bf970929",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Base and Expand 1')\n",
    "print('Linear CKA: {}'.format(linear_CKA(model_b1.layers[1].get_weights()[0], model1.layers[1].get_weights()[0])))\n",
    "print('Kernel CKA: {}'.format(kernel_CKA(model_b1.layers[1].get_weights()[0], model1.layers[1].get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1bcfc-420e-45a0-927f-e8903c82e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Base and Expand 2')\n",
    "print('Linear CKA: {}'.format(linear_CKA(model_b1.layers[1].get_weights()[0], model2.layers[1].get_weights()[0])))\n",
    "print('Kernel CKA: {}'.format(kernel_CKA(model_b1.layers[1].get_weights()[0], model2.layers[1].get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b3009-4b70-4115-8027-a031aaa8b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Base and Random')\n",
    "print('Linear CKA: {}'.format(linear_CKA(model_b1.layers[1].get_weights()[0], model.layers[1].get_weights()[0])))\n",
    "print('Kernel CKA: {}'.format(kernel_CKA(model_b1.layers[1].get_weights()[0], model.layers[1].get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45f9e8-ff17-480d-8327-9a5d5375dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expand 1 and Expand 2')\n",
    "print('Linear CKA: {}'.format(linear_CKA(model1.layers[1].get_weights()[0], model2.layers[1].get_weights()[0])))\n",
    "print('Kernel CKA: {}'.format(kernel_CKA(model1.layers[1].get_weights()[0], model2.layers[1].get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6986c7-3c62-4c1b-b0d0-5d5c37d8f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random and Expand 1')\n",
    "print('Linear CKA: {}'.format(linear_CKA(model.layers[1].get_weights()[0], model1.layers[1].get_weights()[0])))\n",
    "print('Kernel CKA: {}'.format(kernel_CKA(model.layers[1].get_weights()[0], model1.layers[1].get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce8bdf-e867-4649-b1c9-b7fa8b8b4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random and Expand 2')\n",
    "print('Linear CKA: {}'.format(linear_CKA(model.layers[1].get_weights()[0], model2.layers[1].get_weights()[0])))\n",
    "print('Kernel CKA: {}'.format(kernel_CKA(model.layers[1].get_weights()[0], model2.layers[1].get_weights()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b173f085-3171-4ecf-8c99-7e8cd3f1df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b1.layers[1].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680cd40-22cf-4912-9c2d-d0c156b5cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.layers[1].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da1bb3-a7e0-499e-bda0-f50f42411f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.layers[1].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee33ec3-60bb-4896-94c0-c4dfc139faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f93c8-9775-49a4-8168-0862df63f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71e4ee-aff4-4bab-9389-899bd577e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b1.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb4ab4-fa95-42ce-8a0b-3b10a07e6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823459e-29bc-4904-9d62-cc171719d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.layers[1].get_weights()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Federated",
   "language": "python",
   "name": "tff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
